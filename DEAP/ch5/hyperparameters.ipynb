{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters in Machine Learning (ML)\n",
    "\n",
    "These are parameters that are generaly set before the learning process is in action, they dictate the model complexity or how fast it should learn. The correct use of hyperparameters can significalty improve the perfromance of the model. \n",
    "\n",
    "An example of these parameters:\n",
    "* The k value in k-nearest neighbors algorithm\n",
    "* Learning rate value\n",
    "* Number of hidden layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning \n",
    "Because the correct selection of hyperparameters can have a significiant perfromance impact, there is a whole area of research that is going on in this area with many different tequineqes being used https://en.wikipedia.org/wiki/Hyperparameter_optimization. \n",
    "\n",
    "### Grid search\n",
    "\n",
    "The most traiditional way and simple way of hyperparameter tunning is using grid search which is a exhaustive search method, which means it simply goes through a manually selected subset of hyperparameter space. This method can work well when there is a small number of hyperparameters ($hp$) as it can quickly search through all the posibities but as $hp$ becomes large this becomes unfeasible.\n",
    "\n",
    "### Random search\n",
    "\n",
    "Random search is a better form of hyperparameter tunning as it selects the values randomly through the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}